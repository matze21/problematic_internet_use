{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "dd = pd.read_csv('data_dictionary.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "testF = test.columns\n",
    "trainF = train.columns\n",
    "bothF = list(set(testF) & set(trainF))\n",
    "missinF = list(set(trainF)-set(testF))\n",
    "len(bothF),len(testF), len(trainF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df = df.loc[~df.sii.isna()]\n",
    "    seasons = [s for s in df.columns if 'Season' in s]\n",
    "    for s in seasons:\n",
    "        df['isSameSeason'+s] = (df['Basic_Demos-Enroll_Season'] == df[s]).astype(np.int8)\n",
    "    \n",
    "    df = df.loc[df['Physical-Weight'] > 0]\n",
    "    df['BIA-BIA_Fat'] = df['BIA-BIA_Fat'].clip(0,100)\n",
    "\n",
    "    df['activityScore'] = np.where(pd.isna(df['PAQ_A-PAQ_A_Total']) & ~pd.isna(df['PAQ_C-PAQ_C_Total']), df['PAQ_C-PAQ_C_Total'],  # If a is NaN and b is not NaN, use b\n",
    "                np.where(~pd.isna(df['PAQ_A-PAQ_A_Total']) & pd.isna(df['PAQ_C-PAQ_C_Total']), df['PAQ_A-PAQ_A_Total'],  # If a is not NaN and b is NaN, use a\n",
    "                np.where(df['Basic_Demos-Age'] > 13, df['PAQ_A-PAQ_A_Total'], df['PAQ_C-PAQ_C_Total']))) \n",
    "    df['activityScoreSeason'] = np.where(pd.isna(df['PAQ_A-Season']) & ~pd.isna(df['PAQ_C-Season']), df['PAQ_C-Season'],  # If a is NaN and b is not NaN, use b\n",
    "                np.where(~pd.isna(df['PAQ_A-Season']) & pd.isna(df['PAQ_C-Season']), df['PAQ_A-Season'],  # If a is not NaN and b is NaN, use a\n",
    "                np.where(df['Basic_Demos-Age'] > 13, df['PAQ_A-Season'], df['PAQ_C-Season']))) \n",
    "    df=df.drop('Physical-Waist_Circumference',axis=1)\n",
    "    return df\n",
    "\n",
    "noNaDa = train.loc[~train.sii.isna()]\n",
    "noNaDa = transform(noNaDa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaDa.loc[noNaDa['BIA-BIA_BMC']<00]#.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General: we have multiple physical tests:\n",
    "- basics: general stats\n",
    "- physical: bmi, height, weight,..\n",
    "- fitness_endurance: on treadmil\n",
    "- FitnessGram Child: lifting tests\n",
    "- Bio-electric Impedance, fat & water mass,..\n",
    "- Physical Activity Questionnaire: adult vs child \n",
    "- Sleep Disturbance Scale\n",
    "- Internet Use\n",
    "- Parent-Child Internet Addiction Test (only in train)\n",
    "\n",
    "\n",
    "semester: very uniform, no info to target\n",
    "age: more younger childs, not gaussian, linear trend of mean, the older the more likely to have issue\n",
    "sex: more men than women, men are more likely to have issue, categorical feature\n",
    "     women seem to be a bit older when they have issues, linear trend is slightly different (combine features)\n",
    "\n",
    "\n",
    "First strategy:\n",
    "- handle everything as categorical -> quantile transformation of data (less impact of outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quantile encoding of numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns=[]\n",
    "for f in train.select_dtypes(np.float64).columns:\n",
    "    if len(train[f].unique())>30:\n",
    "        numerical_columns.append(f)\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addEncodings(train):\n",
    "    numerical_columns=[]\n",
    "    for f in train.select_dtypes(np.float64).columns:\n",
    "        if len(train[f].unique())>30:\n",
    "            numerical_columns.append(f) \n",
    "\n",
    "    normalDistF = [f+'normalD' for f in numerical_columns]\n",
    "    unifDistF = [f+'unifD' for f in numerical_columns]\n",
    "    qtUnif = QuantileTransformer(n_quantiles=1000, output_distribution='uniform', random_state=42)  \n",
    "    qtNorm = QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=42)  \n",
    "\n",
    "    train[unifDistF] = qtUnif.fit_transform(train[numerical_columns])\n",
    "    train[unifDistF] = qtNorm.fit_transform(train[numerical_columns])\n",
    "\n",
    "    return train, qtUnif, qtNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns=[]\n",
    "for f in train.select_dtypes(np.float64).columns:\n",
    "    if len(train[f].unique())>30:\n",
    "        numerical_columns.append(f)\n",
    "\n",
    "normalDistF = [f+'normalD' for f in numerical_columns]\n",
    "unifDistF = [f+'unifD' for f in numerical_columns]\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='uniform', random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "trainQ = train.copy()\n",
    "trainQ[numerical_columns] = qt.fit_transform(train[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',80)\n",
    "trainQ.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaDa.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',90)\n",
    "noNaDa.loc[(noNaDa['PAQ_A-PAQ_A_Total'].isna() == False) & (noNaDa['PAQ_C-PAQ_C_Total'].isna() == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noNaDa['activityScore'] = np.where(pd.isna(noNaDa['PAQ_A-PAQ_A_Total']) & ~pd.isna(noNaDa['PAQ_C-PAQ_C_Total']), noNaDa['PAQ_C-PAQ_C_Total'],  # If a is NaN and b is not NaN, use b\n",
    "                np.where(~pd.isna(noNaDa['PAQ_A-PAQ_A_Total']) & pd.isna(noNaDa['PAQ_C-PAQ_C_Total']), noNaDa['PAQ_A-PAQ_A_Total'],  # If a is not NaN and b is NaN, use a\n",
    "                np.where(noNaDa['Basic_Demos-Age'] > 13, noNaDa['PAQ_A-PAQ_A_Total'], noNaDa['PAQ_C-PAQ_C_Total']))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaDa[['PAQ_A-PAQ_A_Total','PAQ_C-PAQ_C_Total','activityScore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target\n",
    "\n",
    "- na for a bunch of values\n",
    "- discrete in 0,1,2,3\n",
    "- frequency is going down linearly from 0 (most frequent) to 3  (least frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaDa = train.loc[~train.sii.isna()]\n",
    "noNaDa = noNaDa.loc[noNaDa['Physical-Weight'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',71)\n",
    "noNaDa.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNaDa.sii.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = dict(noNaDa.dtypes)\n",
    "for column, dtype in dtype_dict.items():\n",
    "    print(f\"{column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['id', 'Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "       'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "       'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "       'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "       'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "       'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "       'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "       'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "       'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "       'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "       'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "       'PAQ_C-PAQ_C_Total', 'PCIAT-Season', 'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02',\n",
    "       'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06',\n",
    "       'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10',\n",
    "       'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14',\n",
    "       'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18',\n",
    "       'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total', 'SDS-Season',\n",
    "       'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "       'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "#noNaDa[f].value_counts(), \n",
    "\n",
    "f = 'BIA-BIA_ICW'# feat[5]\n",
    "def eval(f, noNaDa):\n",
    "    print(f)\n",
    "    display(noNaDa[f].isna().sum())\n",
    "    #noNaDa[f].hist(bins=100)\n",
    "    #grouped = noNaDa.groupby('sii')[f].value_counts().unstack().fillna(0)\n",
    "    #grouped = noNaDa.groupby('sii')[f]\n",
    "    min_val = noNaDa[f].min()  # Minimum value across all groups\n",
    "    max_val = noNaDa[f].max()  # Maximum value across all groups\n",
    "    print(min_val, max_val)\n",
    "    # Define the number of bins and calculate bin edges\n",
    "    num_bins = 100\n",
    "    bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for i in noNaDa.sii.unique():\n",
    "        ax.hist(noNaDa.loc[noNaDa.sii==i][f], bins=bins, alpha=0.2, label=i)\n",
    "    plt.title(f'Stacked Bar Plot of {f} grouped by a')\n",
    "    plt.xlabel('a')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title=f, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if noNaDa[f].dtype == np.float64:\n",
    "        sns.violinplot(x=noNaDa['sii'],y=noNaDa[f])\n",
    "    else:\n",
    "        display(pd.crosstab(noNaDa['sii'],noNaDa[f]).style.background_gradient(cmap='viridis'))\n",
    "        display(pd.crosstab(noNaDa['sii'],noNaDa[f], normalize='index').style.background_gradient(cmap='viridis', vmin=0, vmax=1))\n",
    "        display(pd.crosstab(noNaDa['sii'],noNaDa[f], normalize='columns').style.background_gradient(cmap='viridis', vmin=0, vmax=1))\n",
    "eval(f,noNaDa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = noNaDa.groupby('sii')[f]\n",
    "grouped.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = [s for s in trainF if 'Season' in s]\n",
    "modSFeat = []\n",
    "for s in seasons:\n",
    "    #noNaDa['isSameSeason'+s] = (noNaDa['Basic_Demos-Enroll_Season'] == noNaDa[s]).astype(np.int8)\n",
    "    modSFeat.append('isSameSeason'+s)\n",
    "    print(noNaDa['isSameSeason'+s].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bio impedance measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zScore = (noNaDa['BIA-BIA_ICW'] - noNaDa['BIA-BIA_ICW'].mean())/noNaDa['BIA-BIA_ICW'].std()\n",
    "noNaDa['BIA-BIA_ICW'].describe()\n",
    "zScore.dropna().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',81)\n",
    "pd.set_option('display.max_columns',101)\n",
    "noNaDa.loc[noNaDa['BIA-BIA_ICW']>200]#['BIA-BIA_ICW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test#.loc[test['BIA-BIA_ICW']>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## enrolled vs participated season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sex and age relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = noNaDa.loc[noNaDa['Basic_Demos-Sex'] == 0]\n",
    "eval(f,men)\n",
    "women = noNaDa.loc[noNaDa['Basic_Demos-Sex'] == 1]\n",
    "eval(f,women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create reports for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_to_pdf(f, noNaDa, pdf_filename):\n",
    "    c = canvas.Canvas(pdf_filename, pagesize=A4)\n",
    "    width, height = A4\n",
    "\n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(50, height - 50, f\"Analysis of {f}\")\n",
    "\n",
    "    # Missing values\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "    missing_values = noNaDa[f].isna().sum()\n",
    "    c.drawString(50, height - 80, f\"Missing values: {missing_values}\")\n",
    "\n",
    "    # hist\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    noNaDa[f].hist(bins=30)\n",
    "    plt.title(f'Histogram of {f}')\n",
    "    plt.xlabel(f)\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    img_buffer2 = BytesIO()\n",
    "    plt.savefig(img_buffer2, format='png')\n",
    "    img_buffer2.seek(0)\n",
    "    c.drawImage(ImageReader(img_buffer2), 50, height - 350, width=500, height=250)\n",
    "    plt.close()\n",
    "\n",
    "    c.showPage()\n",
    "    # Violin plot or crosstab\n",
    "    if noNaDa[f].dtype == np.float64 and len(noNaDa[f].unique())>20:\n",
    "        zScore =(noNaDa[f]-noNaDa[f].mean())/(noNaDa[f].std())\n",
    "        # hist\n",
    "        noOut = noNaDa#.loc[abs(zScore)<5]\n",
    "        c.drawString(50, height - 810, f\"outliers values: {noNaDa.loc[abs(zScore)>5].shape[0]}\")\n",
    "\n",
    "        fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(5, 1, figsize=(10, 10))\n",
    "        # Violin plot\n",
    "        sns.violinplot(x=noOut['sii'], y=noOut[f], ax=ax1)\n",
    "        ax1.set_title(f'Violin Plot of {f} by sii')\n",
    "        \n",
    "        # Correlation matrix\n",
    "        #corr_matrix = noNaDa[['sii', f]].corr(method='spearman')\n",
    "        #sns.heatmap(corr_matrix, annot=True, cmap='RdBu', ax=ax2, vmin=-1,vmax=1)\n",
    "        #ax2.set_title('Correlation Matrix')\n",
    "        #noOut['siiJitter'] = noOut['sii'] + np.random.random()*.8 - 0.4\n",
    "        noOut=noOut.assign(**{'siiJitter': noOut['sii'] + np.random.random(len(noOut))*.8 -.4})\n",
    "        noOut.plot.scatter(x='siiJitter', y=f, ax=ax2, alpha=0.1)\n",
    "        ax2.set_xlabel('sii jitter')\n",
    "        ax2.set_ylabel(f)\n",
    "        noOut[f].hist(bins=30, ax=ax3)\n",
    "        noOut.plot.hexbin(x='siiJitter', y=f, alpha=1, gridsize=10, ax=ax4)\n",
    "\n",
    "        min_val = noOut[f].min()  # Minimum value across all groups\n",
    "        max_val = noOut[f].max()  # Maximum value across all groups\n",
    "        #print(min_val, max_val)\n",
    "        # Define the number of bins and calculate bin edges\n",
    "        num_bins = 100\n",
    "        bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "        for i in noOut.sii.unique():\n",
    "            ax5.hist(noOut.loc[noOut.sii==i][f], bins=bins, alpha=0.2, label=i)\n",
    "        ax5.set_xlabel(f)\n",
    "        ax5.set_ylabel('frequency')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        img_buffer = BytesIO()\n",
    "        plt.savefig(img_buffer, format='png')\n",
    "        img_buffer.seek(0)\n",
    "        c.drawImage(ImageReader(img_buffer), 50, height - 800, width=500, height=800)\n",
    "        plt.close()\n",
    "\n",
    "        # 'Basic_Demos-Age', 'Basic_Demos-Sex', 'Physical-Height', 'Physical-Weight',\n",
    "        c.showPage()\n",
    "        fig2, (ax1, ax2,ax3,ax4,ax5,ax6) = plt.subplots(6, 1, figsize=(10, 10))\n",
    "        noOut=noOut.assign(**{'ageJitter': noOut['Basic_Demos-Age'] + np.random.random(len(noOut))*.8 -.4})\n",
    "        #noOut.plot.hexbin(x='Basic_Demos-Age', y=f, alpha=1, gridsize=20, ax=ax1)\n",
    "        noOut.plot.scatter(x='ageJitter', y=f, alpha=0.1, ax=ax1)\n",
    "        sns.violinplot(x=noOut['Basic_Demos-Age'], y=noOut[f], ax=ax2)\n",
    "        noOut=noOut.assign(**{'sexJitter': noOut['Basic_Demos-Sex'] + np.random.random(len(noOut))*.8 -.4})\n",
    "        #noOut.plot.hexbin(x='Basic_Demos-Sex', y=f, alpha=1, gridsize=20, ax=ax2)\n",
    "        noOut.plot.scatter(x='sexJitter', y=f, alpha=0.1, ax=ax3)\n",
    "        sns.violinplot(x=noOut['Basic_Demos-Sex'], y=noOut[f], ax=ax4)\n",
    "        noOut.plot.scatter(x='Physical-Height', y=f, alpha=0.1, ax=ax5)\n",
    "        noOut.plot.scatter(x='Physical-Weight', y=f, alpha=0.1, ax=ax6)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        img_buffer = BytesIO()\n",
    "        plt.savefig(img_buffer, format='png')\n",
    "        img_buffer.seek(0)\n",
    "        c.drawImage(ImageReader(img_buffer), 50, height - 800, width=500, height=800)\n",
    "        plt.close()\n",
    "    else:\n",
    "        # Bar plot\n",
    "        grouped = noNaDa.groupby(f)['sii'].value_counts().unstack().fillna(0)\n",
    "        fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(10, 5))\n",
    "        grouped.plot(kind='bar', stacked=False, ax=ax1)\n",
    "        grouped.plot(kind='bar', stacked=True, ax=ax2)\n",
    "        plt.title(f'Bar Plot of {f} grouped by sii')\n",
    "        plt.xlabel(f)\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend(title='sii', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        img_buffer = BytesIO()\n",
    "        plt.savefig(img_buffer, format='png')\n",
    "        img_buffer.seek(0)\n",
    "        c.drawImage(ImageReader(img_buffer), 50, height - 400, width=500, height=250)\n",
    "        plt.close()\n",
    "        c.showPage()\n",
    "        # Create crosstabs\n",
    "        crosstab = pd.crosstab(noNaDa['sii'], noNaDa[f])\n",
    "        crosstab_norm_index = pd.crosstab(noNaDa['sii'], noNaDa[f], normalize='index')\n",
    "        crosstab_norm_columns = pd.crosstab(noNaDa['sii'], noNaDa[f], normalize='columns')\n",
    "\n",
    "        # Function to create and save heatmap\n",
    "        def create_heatmap(data, title,normalized=True):\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            if normalized:\n",
    "                sns.heatmap(data, annot=True, cmap='viridis', fmt='.2f', vmin=0, vmax=1)\n",
    "            else:\n",
    "                sns.heatmap(data, annot=True, cmap='viridis', fmt='.0f')\n",
    "            plt.title(title)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            img_buffer = BytesIO()\n",
    "            plt.savefig(img_buffer, format='png')\n",
    "            img_buffer.seek(0)\n",
    "            return img_buffer\n",
    "\n",
    "        # Create heatmaps\n",
    "        heatmap_regular = create_heatmap(crosstab, 'Crosstab', False)\n",
    "        heatmap_norm_index = create_heatmap(crosstab_norm_index, 'Crosstab (normalized by index)')\n",
    "        heatmap_norm_columns = create_heatmap(crosstab_norm_columns, 'Crosstab (normalized by columns)')\n",
    "\n",
    "        # Add heatmaps to PDF\n",
    "        c.drawImage(ImageReader(heatmap_regular), 50, height - 700, width=500, height=250)\n",
    "        c.showPage()  # New page for normalized crosstabs\n",
    "        c.drawImage(ImageReader(heatmap_norm_index), 50, height - 300, width=500, height=250)\n",
    "        c.drawImage(ImageReader(heatmap_norm_columns), 50, height - 600, width=500, height=250)\n",
    "\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "\n",
    "# Usage\n",
    "if 1:\n",
    "    for i,f in enumerate(tqdm(trainF)):\n",
    "        if f == 'ii' or f =='id':\n",
    "            continue\n",
    "        eval_to_pdf(f, trainQ, 'reportsQuantile/'+str(i)+'output_report'+f+'.pdf')\n",
    "else:\n",
    "    f = 'CGAS-CGAS_Score'\n",
    "    #f = 'BIA-BIA_ICW'\n",
    "    #eval_to_pdf(f, noNaDa, 'output_report'+f+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
